import re
import random
import numpy as np
import math

from sklearn.model_selection import train_test_split

# Limits for randomized weight generated
UPPER = 1
LOWER = -1

# Quick row/col identifiers for easier reading of code
ROWS = 0
COLS = 1

# Identifier for prining feed-forward output variable specifically
OUTPUT = 2

##################################################
# sigmoid( x )
##################################################
def sigmoid( x ):
    if x < 0:
        return 1.0 - 1.0 / ( 1.0 + np.exp( -x ) )
    return 1.0 / ( 1.0 + np.exp( -x ) )

##################################################
# sigmoid'( x )
##################################################
def sigmoid_derivative( x ):
    return x * ( 1 - x )

##################################################
# Read training/testing sets
##################################################
def read_file( file_name ):
    sets = []
    with open( file_name ) as file:
        line = file.readline()
        while line:
            split_line = [val.strip(' ') for val in re.split(r'[()]', line.strip('(' + ')' + '\n'))]

            feature_vector = list( map( int, split_line[1].split(' ') ) )     # Convert string values to integer values
            label_val = int( split_line[2] )                                  # Save Class Value

            # Append new Node object w/ label value, and the feature vector values
            sets.append( (label_val, feature_vector) )

            line = file.readline()
    
    return sets

##################################################
# Convert numberic value into coresponding 
# vector to be using in neural network
##################################################
def convert_output( old_data ):
    upper_lim = max( old_data )[0]

    new_data = []
    for x in old_data:
        new_label = [0] * ( upper_lim + 1 )
        new_label[x[0]] = 1
        new_vector = x[1]

        new_data.append( (new_label, new_vector) )

    return new_data

##################################################
# NeuralNetwork Class
##################################################
class NeuralNetwork:
    def __init__( self, input_nodes, hidden_nodes, output_nodes, learning_rate ):
        self.input_nodes = input_nodes     # 10 Input Nodes [0, . . ., 96] + 1 Bias Input
        self.hidden_nodes = hidden_nodes   # 11 Hidden Nodes + 1 Bias Node
        self.output_nodes = output_nodes        # 8 Output Node [0, . . ., 7]

        self.learning_rate = learning_rate

        # Weights for [ INPUT -> HIDDEN ]
        self.input_weights = np.array( np.random.uniform( LOWER, UPPER, size = (self.hidden_nodes, self.input_nodes + 1) ) )
        # Weights for [ HIDDEN -> OUTPUT ]
        self.output_weights = np.array( np.random.uniform( LOWER, UPPER, size = (self.output_nodes, self.hidden_nodes + 1) ) )

        # Bias for [ INPUT -> HIDDEN ]
        self.hidden_bias = 1
        # Bias for [ HIDDEN -> OUTPUT ]
        self.output_bias = 1

    def feed_forward( self, x ):
        # Vectorized sigmoid function to take a numpy array as input and returns a numpy array as output
        sigmoid_function = np.vectorize( sigmoid )

        inputs = np.array( x )
        inputs = inputs.reshape( len( x ), 1 )
        inputs = np.vstack([inputs, [[self.hidden_bias]]] )       # Add bias value
       
        # hidden = weight x inputs
        hidden = self.input_weights.dot( inputs )
    
        # activation function
        hidden = sigmoid_function( hidden )
        hidden = np.vstack([hidden,  [[self.output_bias]]] )       # Add bias value

        # output = weight x hidden 
        outputs = self.output_weights.dot( hidden )
        # activation function
        outputs = sigmoid_function( outputs )

        # Return List
        return ( inputs, hidden, outputs )

    def train( self, x, targets ):
        # Vectorized sigmoid derivative function to take a numpy array as input and returns a numpy array as output
        sigmoid_derivative_function = np.vectorize( sigmoid_derivative )

        # Feed-Forward
        inputs, hidden, outputs = self.feed_forward( x )

        # Calculate errors
        output_error = np.array( targets ).reshape(len(targets), 1) - outputs
        hidden_error = np.dot( self.output_weights.T, output_error )

        # Calculate output gradiant = [ lr * E * sigmoid'(outputs) ]
        output_gradient = self.learning_rate * output_error * sigmoid_derivative_function( outputs )

        # Calculate hidden->output deltas
        output_deltas = np.dot( output_gradient, hidden.T )

        # Adjust hidden->output weights by deltas
        self.output_weights = np.add( self.output_weights, output_deltas )

        # Remove row generated by bias. No effect when removed
        hidden = np.delete( hidden, (len( hidden) - 1), axis = ROWS)
        # Remove row generated by bias. No effect when removed
        hidden_error = np.delete( hidden_error, (len( hidden_error) - 1), axis = ROWS)

        # Calculate hidden gradiant
        hidden_gradient = self.learning_rate * hidden_error * sigmoid_derivative_function( hidden )

        # Calculate input->hidden deltas
        hidden_deltas = np.dot( hidden_gradient, inputs.T )

        # Adjust hidden->output weights by deltas
        self.input_weights = np.add( self.input_weights, hidden_deltas )

##################################################
# Main
##################################################
def main():
    training_set = convert_output( read_file( 'training_vectors.txt' ) )
    testing_set = read_file( 'training_vectors.txt' )

    correct = 0
    epochs = 22

    n = NeuralNetwork( 10, 10, 8, 0.05 )

    print( "Pre-Training [INPUT->HIDDEN] Weigths:", '\n', n.input_weights, '\n' )
    print( "Pre-Training [HIDDEN->OUTPUT] Weigths:", '\n', n.output_weights, '\n' )

    print( "[ TRAINING . . . . ]" )
    for _ in range( epochs ):
        training_data = random.choice( training_set )
        n.train( training_data[1], training_data[0] )

    print( "Post-Training [INPUT->HIDDEN] Weigths:", '\n', n.input_weights, '\n' )
    print( "Post-Training [HIDDEN->OUTPUT] Weigths:", '\n', n.output_weights, '\n\n' )

    print( "Number of Epochs: ", epochs, '\n\n')

    print( "[ GUESSING . . . . ]" )
    for test_elm in testing_set:
        guessed_results = n.feed_forward( test_elm[1] )[OUTPUT].flatten().tolist()
        guess = guessed_results.index(max(guessed_results))

        if guess is test_elm[0]:
            correct += 1

    print( "Guesses Percentage = ", (100 * float(correct)/float(len(testing_set))), "% Correct" )


if __name__ == "__main__":
    main()